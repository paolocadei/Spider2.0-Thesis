{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3715fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fastembed.sparse.bm25 import Bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bb5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/paolocadei/Documents/Masters/Thesis/Spider2/2_final_structure_all.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9cc38",
   "metadata": {},
   "source": [
    "### BM25 Sparse Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e770677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loaded existing embeddings from 4_bm25_embeddings.json.gz.\n",
      "\n",
      "üìã Total columns: 134095\n",
      "‚úÖ Already embedded: 134095\n",
      "üìù To embed now: 0\n",
      "\n",
      "üì¶ Total batches created: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding columns (BM25): 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed 0 new BM25 embeddings in 0.00 seconds.\n",
      "üìà Total embeddings now stored: 134095/134095\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fastembed.sparse.bm25 import Bm25\n",
    "\n",
    "# === SETTINGS ===\n",
    "SAVE_EVERY = 5000                      # Save every N embeddings\n",
    "SAVE_PATH = \"4_bm25_embeddings.json.gz\"  # Output path (compressed)\n",
    "MAX_WORKERS = 100                      # Thread pool size\n",
    "BATCH_SIZE = 100                       # Texts per batch\n",
    "\n",
    "# === INITIALIZATION ===\n",
    "bm25_embedding_model = Bm25(\"Qdrant/bm25\")\n",
    "new_embeddings = {}\n",
    "total_embeddings_done = 0\n",
    "texts_to_embed = []\n",
    "\n",
    "# === NUMPY SERIALIZATION FIX ===\n",
    "\n",
    "def convert_numpy(obj):\n",
    "    \"\"\"Recursively convert NumPy arrays to lists inside any structure.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy(v) for v in obj]\n",
    "    elif hasattr(obj, 'tolist'):  # for np.ndarray\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# === SAFE LOAD FUNCTIONS ===\n",
    "\n",
    "def safe_load_json(path):\n",
    "    try:\n",
    "        with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        print(f\"‚ö†Ô∏è Warning: {path} is corrupted or missing. Starting fresh.\")\n",
    "        return {}\n",
    "\n",
    "def save_embeddings_to_file():\n",
    "    tmp_save_path = SAVE_PATH + \".tmp\"\n",
    "    with gzip.open(tmp_save_path, 'wt', encoding='utf-8') as f:\n",
    "        json.dump(convert_numpy(new_embeddings), f)\n",
    "    os.replace(tmp_save_path, SAVE_PATH)\n",
    "\n",
    "# === LOAD EXISTING EMBEDDINGS ===\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    new_embeddings = safe_load_json(SAVE_PATH)\n",
    "    print(f\"üîÑ Loaded existing embeddings from {SAVE_PATH}.\")\n",
    "else:\n",
    "    print(f\"üÜï No existing embeddings found. Starting fresh.\")\n",
    "\n",
    "# === EMBEDDING FUNCTION ===\n",
    "def get_bm25_embeddings_batch(texts):\n",
    "    \"\"\"Generate BM25 sparse embeddings.\"\"\"\n",
    "    return list(bm25_embedding_model.passage_embed(texts))\n",
    "\n",
    "# === GATHER TEXTS TO EMBED ===\n",
    "\n",
    "for database in data:\n",
    "    if database not in new_embeddings:\n",
    "        new_embeddings[database] = {}\n",
    "\n",
    "    for table in data[database]:\n",
    "        if table not in new_embeddings[database]:\n",
    "            new_embeddings[database][table] = {'grouped': {}, 'ungrouped': {}}\n",
    "\n",
    "        # GROUPED\n",
    "        for template in data[database][table].get('grouped', {}):\n",
    "            if template not in new_embeddings[database][table]['grouped']:\n",
    "                new_embeddings[database][table]['grouped'][template] = []\n",
    "\n",
    "            for group_index, group_entry in enumerate(data[database][table]['grouped'][template]):\n",
    "                column_descriptions = group_entry['details']['description']\n",
    "\n",
    "                # Ensure exact group_index alignment\n",
    "                while len(new_embeddings[database][table]['grouped'][template]) <= group_index:\n",
    "                    new_embeddings[database][table]['grouped'][template].append({\n",
    "                        'details': {'column_embeddings': {}}\n",
    "                    })\n",
    "\n",
    "                for col_name, col_description in column_descriptions.items():\n",
    "                    if not col_description:\n",
    "                        continue\n",
    "\n",
    "                    already_embedded = col_name in new_embeddings[database][table]['grouped'][template][group_index]['details']['column_embeddings']\n",
    "                    if already_embedded:\n",
    "                        total_embeddings_done += 1\n",
    "                    else:\n",
    "                        texts_to_embed.append((database, table, ('grouped', template, group_index), col_name, col_description))\n",
    "\n",
    "        # UNGROUPED\n",
    "        for ungrouped_key, ungrouped_entry in data[database][table].get('ungrouped', {}).items():\n",
    "            if ungrouped_key not in new_embeddings[database][table]['ungrouped']:\n",
    "                new_embeddings[database][table]['ungrouped'][ungrouped_key] = {\n",
    "                    'details': {'column_embeddings': {}}\n",
    "                }\n",
    "\n",
    "            column_descriptions = ungrouped_entry['details']['description']\n",
    "\n",
    "            for col_name, col_description in column_descriptions.items():\n",
    "                if not col_description:\n",
    "                    continue\n",
    "\n",
    "                already_embedded = col_name in new_embeddings[database][table]['ungrouped'][ungrouped_key]['details']['column_embeddings']\n",
    "                if already_embedded:\n",
    "                    total_embeddings_done += 1\n",
    "                else:\n",
    "                    texts_to_embed.append((database, table, ('ungrouped', ungrouped_key), col_name, col_description))\n",
    "\n",
    "# === DISPLAY PROGRESS COUNTS ===\n",
    "total_columns = total_embeddings_done + len(texts_to_embed)\n",
    "print(f\"\\nüìã Total columns: {total_columns}\")\n",
    "print(f\"‚úÖ Already embedded: {total_embeddings_done}\")\n",
    "print(f\"üìù To embed now: {len(texts_to_embed)}\\n\")\n",
    "\n",
    "# === BATCHING ===\n",
    "batches = [texts_to_embed[i:i + BATCH_SIZE] for i in range(0, len(texts_to_embed), BATCH_SIZE)]\n",
    "\n",
    "print(f\"üì¶ Total batches created: {len(batches)}\")\n",
    "\n",
    "# === PARALLEL EXECUTION ===\n",
    "executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
    "futures = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=len(texts_to_embed), desc=\"Embedding columns (BM25)\") as pbar:\n",
    "    for batch in batches:\n",
    "        texts_only = [item[4] for item in batch]\n",
    "        future = executor.submit(get_bm25_embeddings_batch, texts_only)\n",
    "        futures.append((future, batch))\n",
    "\n",
    "    for future, batch in futures:\n",
    "        embeddings = future.result()\n",
    "        for (database, table, location, col_name, _), embedding in zip(batch, embeddings):\n",
    "\n",
    "            emb_obj = embedding.as_object()\n",
    "\n",
    "            if location[0] == 'grouped':\n",
    "                template, index = location[1], location[2]\n",
    "                new_embeddings[database][table]['grouped'][template][index]['details']['column_embeddings'][col_name] = emb_obj\n",
    "            else:\n",
    "                ungrouped_key = location[1]\n",
    "                new_embeddings[database][table]['ungrouped'][ungrouped_key]['details']['column_embeddings'][col_name] = emb_obj\n",
    "\n",
    "            total_embeddings_done += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if total_embeddings_done % SAVE_EVERY == 0:\n",
    "                save_embeddings_to_file()\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# === FINAL SAVE ===\n",
    "save_embeddings_to_file()\n",
    "\n",
    "print(f\"\\n‚úÖ Completed {len(texts_to_embed)} new BM25 embeddings in {elapsed:.2f} seconds.\")\n",
    "print(f\"üìà Total embeddings now stored: {total_embeddings_done}/{total_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea611a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File loaded successfully.\n",
      "üî¢ Top-level databases: ['NEW_YORK', 'SEC_QUARTERLY_FINANCIALS', 'NHTSA_TRAFFIC_FATALITIES_PLUS']\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "with gzip.open(\"bm25_embeddings.json.gz\", 'rt', encoding='utf-8') as f:\n",
    "    embeddings = json.load(f)\n",
    "\n",
    "print(\"‚úÖ File loaded successfully.\")\n",
    "print(f\"üî¢ Top-level databases: {list(embeddings.keys())[:3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91a4b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Example embedding object:\n",
      "{\n",
      "  \"ehail_fee\": {\n",
      "    \"values\": [\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652,\n",
      "      1.6348330914368652\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      572975545,\n",
      "      1479387819,\n",
      "      1034183227,\n",
      "      70273945,\n",
      "      804460016,\n",
      "      799141647,\n",
      "      1598178082,\n",
      "      292767579,\n",
      "      962346254,\n",
      "      94597757,\n",
      "      1634657082,\n",
      "      1883650607,\n",
      "      2095749492\n",
      "    ]\n",
      "  },\n",
      "  \"mta_tax\": {\n",
      "    \"values\": [\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404,\n",
      "      1.6477472205968404\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      764297089,\n",
      "      118156056,\n",
      "      205716527,\n",
      "      1640465690,\n",
      "      1303311199,\n",
      "      1676999396,\n",
      "      1010104944,\n",
      "      346898420,\n",
      "      1151308235,\n",
      "      640124220\n",
      "    ]\n",
      "  },\n",
      "  \"dropoff_datetime\": {\n",
      "    \"values\": [\n",
      "      1.6741973840665876,\n",
      "      1.6741973840665876,\n",
      "      1.6741973840665876,\n",
      "      1.6741973840665876\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      718402331,\n",
      "      2058513491,\n",
      "      346898420,\n",
      "      2026473737\n",
      "    ]\n",
      "  },\n",
      "  \"tip_amount\": {\n",
      "    \"values\": [\n",
      "      1.9768339768339769,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614,\n",
      "      1.6434199007878614\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      877304949,\n",
      "      1235209082,\n",
      "      1921709490,\n",
      "      1303311199,\n",
      "      710973585,\n",
      "      1115203559,\n",
      "      245350191,\n",
      "      1755936491,\n",
      "      1341778817\n",
      "    ]\n",
      "  },\n",
      "  \"extra\": {\n",
      "    \"values\": [\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362,\n",
      "      1.6391152502910362\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      602020600,\n",
      "      427317956,\n",
      "      2120853021,\n",
      "      407983593,\n",
      "      1341778817,\n",
      "      764297089,\n",
      "      118156056,\n",
      "      1810453357,\n",
      "      1212879818,\n",
      "      446617493,\n",
      "      1789311006,\n",
      "      70273945\n",
      "    ]\n",
      "  },\n",
      "  \"dropoff_latitude\": {\n",
      "    \"values\": [\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1372098455,\n",
      "      346898420,\n",
      "      2058513491\n",
      "    ]\n",
      "  },\n",
      "  \"pickup_datetime\": {\n",
      "    \"values\": [\n",
      "      1.6741973840665876,\n",
      "      1.6741973840665876,\n",
      "      1.6741973840665876,\n",
      "      1.6741973840665876\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      718402331,\n",
      "      2058513491,\n",
      "      346898420,\n",
      "      712299080\n",
      "    ]\n",
      "  },\n",
      "  \"passenger_count\": {\n",
      "    \"values\": [\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1308688855,\n",
      "      527980498,\n",
      "      204076397,\n",
      "      1915816983,\n",
      "      1296773219,\n",
      "      1289414591\n",
      "    ]\n",
      "  },\n",
      "  \"total_amount\": {\n",
      "    \"values\": [\n",
      "      1.6608670008846949,\n",
      "      1.6608670008846949,\n",
      "      1.6608670008846949,\n",
      "      1.6608670008846949,\n",
      "      1.6608670008846949,\n",
      "      1.6608670008846949,\n",
      "      1.6608670008846949\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1214258741,\n",
      "      1235209082,\n",
      "      70273945,\n",
      "      527980498,\n",
      "      1341778817,\n",
      "      1755936491,\n",
      "      877304949\n",
      "    ]\n",
      "  },\n",
      "  \"time_between_service\": {\n",
      "    \"values\": [\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.853546157643574,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.853546157643574,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067,\n",
      "      1.601364799545067\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      699539807,\n",
      "      1479387819,\n",
      "      2058513491,\n",
      "      1434869899,\n",
      "      436751995,\n",
      "      939215365,\n",
      "      2037283124,\n",
      "      1499890166,\n",
      "      1678726688,\n",
      "      1561499504,\n",
      "      2120095081,\n",
      "      1342301861,\n",
      "      930883039,\n",
      "      204076397,\n",
      "      1563718956,\n",
      "      614665414,\n",
      "      100532018,\n",
      "      914661744,\n",
      "      103767893\n",
      "    ]\n",
      "  },\n",
      "  \"pickup_longitude\": {\n",
      "    \"values\": [\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      686482701,\n",
      "      346898420,\n",
      "      712299080\n",
      "    ]\n",
      "  },\n",
      "  \"fare_amount\": {\n",
      "    \"values\": [\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      2058513491,\n",
      "      771638685,\n",
      "      1308081548,\n",
      "      1230423685,\n",
      "      346898420\n",
      "    ]\n",
      "  },\n",
      "  \"imp_surcharge\": {\n",
      "    \"values\": [\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.872963086132358,\n",
      "      1.872963086132358,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      764297089,\n",
      "      749129358,\n",
      "      2012469550,\n",
      "      2120853021,\n",
      "      119240421,\n",
      "      1598178082,\n",
      "      1678726688,\n",
      "      233592972,\n",
      "      324964102,\n",
      "      732690489,\n",
      "      1508921895,\n",
      "      1293336596\n",
      "    ]\n",
      "  },\n",
      "  \"store_and_fwd_flag\": {\n",
      "    \"values\": [\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.9521663778162912,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.8480721903199344,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.9521663778162912,\n",
      "      1.9521663778162912,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934,\n",
      "      1.5932107496463934\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      233592972,\n",
      "      1563317370,\n",
      "      2122579230,\n",
      "      1678726688,\n",
      "      1536651520,\n",
      "      1886380664,\n",
      "      204076397,\n",
      "      1903244910,\n",
      "      1647276219,\n",
      "      1048741621,\n",
      "      882820413,\n",
      "      546776626,\n",
      "      2136405083,\n",
      "      1223115691,\n",
      "      548955463,\n",
      "      967714644\n",
      "    ]\n",
      "  },\n",
      "  \"distance_between_service\": {\n",
      "    \"values\": [\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.861818181818182,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913,\n",
      "      1.6137535816618913\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1959556456,\n",
      "      699539807,\n",
      "      1536651520,\n",
      "      1124580248,\n",
      "      771638685,\n",
      "      273066799,\n",
      "      1342301861,\n",
      "      2092953102,\n",
      "      1678726688,\n",
      "      1365144653,\n",
      "      1548713000,\n",
      "      1070064657,\n",
      "      446319932,\n",
      "      914661744,\n",
      "      825292241,\n",
      "      1183495594,\n",
      "      1856538418\n",
      "    ]\n",
      "  },\n",
      "  \"dropoff_longitude\": {\n",
      "    \"values\": [\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      686482701,\n",
      "      346898420,\n",
      "      2058513491\n",
      "    ]\n",
      "  },\n",
      "  \"payment_type\": {\n",
      "    \"values\": [\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.856295319709954,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      727594685,\n",
      "      1853176582,\n",
      "      1414758646,\n",
      "      527980498,\n",
      "      1563803460,\n",
      "      1678726688,\n",
      "      1810453357,\n",
      "      1115203559,\n",
      "      245350191,\n",
      "      19522071,\n",
      "      1755936491,\n",
      "      264741300,\n",
      "      70273945,\n",
      "      516830072,\n",
      "      197435570,\n",
      "      1394226660,\n",
      "      575491131,\n",
      "      670727360,\n",
      "      7592522\n",
      "    ]\n",
      "  },\n",
      "  \"vendor_id\": {\n",
      "    \"values\": [\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.872963086132358,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436,\n",
      "      1.6305732484076436\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1853176582,\n",
      "      1563317370,\n",
      "      1651016532,\n",
      "      1563718956,\n",
      "      1536651520,\n",
      "      1810453357,\n",
      "      1412784057,\n",
      "      94597757,\n",
      "      575755316,\n",
      "      1979141551,\n",
      "      19522071,\n",
      "      346103956,\n",
      "      1593332629\n",
      "    ]\n",
      "  },\n",
      "  \"trip_distance\": {\n",
      "    \"values\": [\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606,\n",
      "      1.6652868125369606\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1816433010,\n",
      "      1678726688,\n",
      "      771638685,\n",
      "      1548713000,\n",
      "      62221562,\n",
      "      1526100991\n",
      "    ]\n",
      "  },\n",
      "  \"rate_code\": {\n",
      "    \"values\": [\n",
      "      1.5972773681225185,\n",
      "      1.8508051265198817,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185,\n",
      "      1.5972773681225185\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1458396614,\n",
      "      1151308235,\n",
      "      1853176582,\n",
      "      243669559,\n",
      "      939215365,\n",
      "      1678726688,\n",
      "      1810453357,\n",
      "      964658953,\n",
      "      19522071,\n",
      "      437044182,\n",
      "      264741300,\n",
      "      1153460869,\n",
      "      516830072,\n",
      "      1668398641,\n",
      "      645691173,\n",
      "      1394226660,\n",
      "      659997964,\n",
      "      1308081548,\n",
      "      670727360,\n",
      "      1021187622,\n",
      "      292767579\n",
      "    ]\n",
      "  },\n",
      "  \"tolls_amount\": {\n",
      "    \"values\": [\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084,\n",
      "      1.6697302104951084\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1214258741,\n",
      "      1235209082,\n",
      "      698153137,\n",
      "      1563803460,\n",
      "      1678726688\n",
      "    ]\n",
      "  },\n",
      "  \"trip_type\": {\n",
      "    \"values\": [\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.856295319709954,\n",
      "      1.856295319709954,\n",
      "      1.856295319709954,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031,\n",
      "      1.6054732041049031\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1853176582,\n",
      "      1563317370,\n",
      "      2122579230,\n",
      "      1678726688,\n",
      "      1421544012,\n",
      "      1598178082,\n",
      "      1883650607,\n",
      "      1303311199,\n",
      "      1679435792,\n",
      "      1010104944,\n",
      "      346898420,\n",
      "      1151308235,\n",
      "      640124220,\n",
      "      354307472,\n",
      "      1915816983,\n",
      "      1810453357,\n",
      "      19522071\n",
      "    ]\n",
      "  },\n",
      "  \"pickup_latitude\": {\n",
      "    \"values\": [\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642,\n",
      "      1.6786885245901642\n",
      "    ],\n",
      "    \"indices\": [\n",
      "      1372098455,\n",
      "      346898420,\n",
      "      712299080\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example = next(iter(embeddings.values()))  # First database\n",
    "example_table = next(iter(example.values()))\n",
    "example_grouped = example_table['grouped']\n",
    "first_template = next(iter(example_grouped))\n",
    "first_entry = example_grouped[first_template][0]\n",
    "print(\"üìÑ Example embedding object:\")\n",
    "print(json.dumps(first_entry['details']['column_embeddings'], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11697421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All good!\n"
     ]
    }
   ],
   "source": [
    "missing = 0\n",
    "\n",
    "for db in data:\n",
    "    for table in data[db]:\n",
    "        for group_type in ['grouped', 'ungrouped']:\n",
    "            entries = data[db][table].get(group_type, {})\n",
    "            for key, entry in entries.items():\n",
    "                if group_type == 'grouped':\n",
    "                    for i, g in enumerate(entry):\n",
    "                        for col in g['details']['description']:\n",
    "                            try:\n",
    "                                embeddings[db][table]['grouped'][key][i]['details']['column_embeddings'][col]\n",
    "                            except KeyError:\n",
    "                                print(db, table, i, col)\n",
    "                                missing += 1\n",
    "                else:\n",
    "                    for col in entry['details']['description']:\n",
    "                        try:\n",
    "                            embeddings[db][table]['ungrouped'][key]['details']['column_embeddings'][col]\n",
    "                        except KeyError:\n",
    "                            missing += 1\n",
    "\n",
    "print(f\"‚úÖ All good!\" if missing == 0 else f\"‚ö†Ô∏è {missing} columns missing embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19febb",
   "metadata": {},
   "source": [
    "### Late Interaction Embeddings\n",
    "\n",
    "Not feasible on a MacBook Pro if use of from fastembed.late_interaction import LateInteractionTextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5bbb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'colbert-ir/colbertv2.0',\n",
       "  'sources': {'hf': 'colbert-ir/colbertv2.0',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Late interaction model',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.44,\n",
       "  'additional_files': [],\n",
       "  'dim': 128,\n",
       "  'tasks': {}},\n",
       " {'model': 'answerdotai/answerai-colbert-small-v1',\n",
       "  'sources': {'hf': 'answerdotai/answerai-colbert-small-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'vespa_colbert.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, 2024 year',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 96,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-colbert-v2',\n",
       "  'sources': {'hf': 'jinaai/jina-colbert-v2',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'New model that expands capabilities of colbert-v1 with multilingual and context length of 8192, 2024 year',\n",
       "  'license': 'cc-by-nc-4.0',\n",
       "  'size_in_GB': 2.24,\n",
       "  'additional_files': ['onnx/model.onnx_data'],\n",
       "  'dim': 128,\n",
       "  'tasks': {}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastembed import LateInteractionTextEmbedding\n",
    "\n",
    "LateInteractionTextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a62d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loaded existing embeddings from colbert_embeddings.json.gz.\n",
      "\n",
      "üìã Total columns: 134095\n",
      "‚úÖ Already embedded: 900\n",
      "üìù To embed now: 133195\n",
      "\n",
      "üì¶ Total batches created: 133195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding columns (ColBERT):   0%|          | 100/133195 [00:12<4:29:02,  8.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m total_embeddings_done \u001b[38;5;241m%\u001b[39m SAVE_EVERY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 156\u001b[0m                 \u001b[43msave_embeddings_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# === FINAL SAVE ===\u001b[39;00m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36msave_embeddings_to_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m tmp_save_path \u001b[38;5;241m=\u001b[39m SAVE_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(tmp_save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(tmp_save_path, SAVE_PATH)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/gzip.py:288\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    285\u001b[0m     length \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcrc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fastembed.late_interaction import LateInteractionTextEmbedding\n",
    "\n",
    "# === SETTINGS ===\n",
    "SAVE_EVERY = 100\n",
    "SAVE_PATH = \"colbert_embeddings.json.gz\"\n",
    "MAX_WORKERS = 5\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# === INITIALIZATION ===\n",
    "late_embedding_model = LateInteractionTextEmbedding(\"answerdotai/answerai-colbert-small-v1\")\n",
    "new_embeddings = {}\n",
    "total_embeddings_done = 0\n",
    "texts_to_embed = []\n",
    "\n",
    "# === NUMPY SERIALIZATION FIX ===\n",
    "def convert_numpy(obj):\n",
    "    \"\"\"Recursively convert NumPy arrays to lists inside any structure.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy(v) for v in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif hasattr(obj, 'tolist'):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# === SAFE LOAD FUNCTIONS ===\n",
    "def safe_load_json(path):\n",
    "    try:\n",
    "        with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        print(f\"‚ö†Ô∏è Warning: {path} is corrupted or missing. Starting fresh.\")\n",
    "        return {}\n",
    "\n",
    "def save_embeddings_to_file():\n",
    "    tmp_save_path = SAVE_PATH + \".tmp\"\n",
    "    with gzip.open(tmp_save_path, 'wt', encoding='utf-8') as f:\n",
    "        json.dump(convert_numpy(new_embeddings), f)\n",
    "    os.replace(tmp_save_path, SAVE_PATH)\n",
    "\n",
    "# === LOAD EXISTING EMBEDDINGS ===\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    new_embeddings = safe_load_json(SAVE_PATH)\n",
    "    print(f\"üîÑ Loaded existing embeddings from {SAVE_PATH}.\")\n",
    "else:\n",
    "    print(f\"üÜï No existing embeddings found. Starting fresh.\")\n",
    "\n",
    "# === EMBEDDING FUNCTION ===\n",
    "def get_late_interaction_embeddings_batch(texts):\n",
    "    return list(late_embedding_model.passage_embed(texts))\n",
    "\n",
    "# === GATHER TEXTS TO EMBED ===\n",
    "for database in data:\n",
    "    if database not in new_embeddings:\n",
    "        new_embeddings[database] = {}\n",
    "\n",
    "    for table in data[database]:\n",
    "        if table not in new_embeddings[database]:\n",
    "            new_embeddings[database][table] = {'grouped': {}, 'ungrouped': {}}\n",
    "\n",
    "        # GROUPED\n",
    "        for template in data[database][table].get('grouped', {}):\n",
    "            if template not in new_embeddings[database][table]['grouped']:\n",
    "                new_embeddings[database][table]['grouped'][template] = []\n",
    "\n",
    "            for group_index, group_entry in enumerate(data[database][table]['grouped'][template]):\n",
    "                column_descriptions = group_entry['details']['description']\n",
    "\n",
    "                while len(new_embeddings[database][table]['grouped'][template]) <= group_index:\n",
    "                    new_embeddings[database][table]['grouped'][template].append({\n",
    "                        'details': {'column_embeddings': {}}\n",
    "                    })\n",
    "\n",
    "                for col_name, col_description in column_descriptions.items():\n",
    "                    if not col_description:\n",
    "                        continue\n",
    "\n",
    "                    already_embedded = col_name in new_embeddings[database][table]['grouped'][template][group_index]['details']['column_embeddings']\n",
    "                    if already_embedded:\n",
    "                        total_embeddings_done += 1\n",
    "                    else:\n",
    "                        texts_to_embed.append((database, table, ('grouped', template, group_index), col_name, col_description))\n",
    "\n",
    "        # UNGROUPED\n",
    "        for ungrouped_key, ungrouped_entry in data[database][table].get('ungrouped', {}).items():\n",
    "            if ungrouped_key not in new_embeddings[database][table]['ungrouped']:\n",
    "                new_embeddings[database][table]['ungrouped'][ungrouped_key] = {\n",
    "                    'details': {'column_embeddings': {}}\n",
    "                }\n",
    "\n",
    "            column_descriptions = ungrouped_entry['details']['description']\n",
    "\n",
    "            for col_name, col_description in column_descriptions.items():\n",
    "                if not col_description:\n",
    "                    continue\n",
    "\n",
    "                already_embedded = col_name in new_embeddings[database][table]['ungrouped'][ungrouped_key]['details']['column_embeddings']\n",
    "                if already_embedded:\n",
    "                    total_embeddings_done += 1\n",
    "                else:\n",
    "                    texts_to_embed.append((database, table, ('ungrouped', ungrouped_key), col_name, col_description))\n",
    "\n",
    "# === DISPLAY PROGRESS ===\n",
    "total_columns = total_embeddings_done + len(texts_to_embed)\n",
    "print(f\"\\nüìã Total columns: {total_columns}\")\n",
    "print(f\"‚úÖ Already embedded: {total_embeddings_done}\")\n",
    "print(f\"üìù To embed now: {len(texts_to_embed)}\\n\")\n",
    "\n",
    "# === BATCHING ===\n",
    "batches = [texts_to_embed[i:i + BATCH_SIZE] for i in range(0, len(texts_to_embed), BATCH_SIZE)]\n",
    "print(f\"üì¶ Total batches created: {len(batches)}\")\n",
    "\n",
    "# === PARALLEL EXECUTION ===\n",
    "executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
    "futures = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tqdm(total=len(texts_to_embed), desc=\"Embedding columns (ColBERT)\") as pbar:\n",
    "    for batch in batches:\n",
    "        texts_only = [item[4] for item in batch]\n",
    "        future = executor.submit(get_late_interaction_embeddings_batch, texts_only)\n",
    "        futures.append((future, batch))\n",
    "\n",
    "    for future, batch in futures:\n",
    "        embeddings = future.result()\n",
    "        for (database, table, location, col_name, _), embedding in zip(batch, embeddings):\n",
    "\n",
    "            # ‚úÖ FIX: Handle both object and array cases\n",
    "            if hasattr(embedding, \"as_object\"):\n",
    "                emb_obj = embedding.as_object()\n",
    "            else:\n",
    "                emb_obj = convert_numpy(embedding)\n",
    "\n",
    "            if location[0] == 'grouped':\n",
    "                template, index = location[1], location[2]\n",
    "                new_embeddings[database][table]['grouped'][template][index]['details']['column_embeddings'][col_name] = emb_obj\n",
    "            else:\n",
    "                ungrouped_key = location[1]\n",
    "                new_embeddings[database][table]['ungrouped'][ungrouped_key]['details']['column_embeddings'][col_name] = emb_obj\n",
    "\n",
    "            total_embeddings_done += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if total_embeddings_done % SAVE_EVERY == 0:\n",
    "                save_embeddings_to_file()\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# === FINAL SAVE ===\n",
    "save_embeddings_to_file()\n",
    "\n",
    "print(f\"\\n‚úÖ Completed {len(texts_to_embed)} ColBERT embeddings in {elapsed:.2f} seconds.\")\n",
    "print(f\"üìà Total embeddings now stored: {total_embeddings_done}/{total_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29372a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229b180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
